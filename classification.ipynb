{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data set\n",
    "\n",
    "We will predict the incidence of diabetes based on various measurements (see [description](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)). Instead of directly using the raw data, we use a normalised version, where the label to be predicted (the incidence of diabetes) is in the first column. Download the data from [the course website](https://machlearn.gitlab.io/isml2017/tutorial/diabetes_scale.csv).\n",
    "\n",
    "Read in the data using ```np.loadtxt```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.63994726,  0.84832379,  0.14964075,  0.90726993,\n",
       "        -0.69289057,  0.20401277,  0.46849198,  1.4259954 ],\n",
       "       [ 0.        , -0.84488505, -1.12339636, -0.16054575,  0.53090156,\n",
       "        -0.69289057, -0.68442195, -0.36506078, -0.19067191],\n",
       "       [ 1.        ,  1.23388019,  1.94372388, -0.26394125, -1.28821221,\n",
       "        -0.69289057, -1.10325546,  0.60439732, -0.10558415],\n",
       "       [ 0.        , -0.84488505, -0.99820778, -0.16054575,  0.15453319,\n",
       "         0.12330164, -0.49404308, -0.92076261, -1.04154944],\n",
       "       [ 1.        , -1.14185152,  0.5040552 , -1.50468724,  0.90726993,\n",
       "         0.76583594,  1.4097456 ,  5.4849091 , -0.0204964 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "names = ['diabetes', 'num preg', 'plasma', 'bp', 'skin fold', 'insulin', 'bmi', 'pedigree', 'age']\n",
    "data = np.loadtxt('diabetes_scale.csv', delimiter=',')\n",
    "# Replace -1 with 0 because we need labels to be in {0, 1}\n",
    "idx = np.where(data[:,0] < 0)\n",
    "data[idx,0] = 0\n",
    "data[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification via Logistic Regression\n",
    "\n",
    "Implementation of binary classification using logistic regression for a data set with two classes.\n",
    "Using ```scipy.optimize.fmin_bfgs``` to optimise your cost function. ```fmin_bfgs``` requires the cost function to be optimised, and the gradient of this cost function. \n",
    "Implementation of the function ```train``` that takes a matrix of examples, and a vector of labels, and returns the maximum likelihood weight vector for logistic regresssion. Also implement a function ```test``` that takes this maximum likelihood weight vector and the a matrix of examples, and returns the predictions. See the section **Putting everything together** below for expected usage.\n",
    "\n",
    "We add an extra column of ones to represent the constant basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack([data, np.ones((data.shape[0], 1))]) # add a column of ones\n",
    "data[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    \"\"\"S shaped function, known as the sigmoid\"\"\"\n",
    "    return 1 / (1 + np.exp(- X))\n",
    "\n",
    "def cost(theta, X, y):\n",
    "    \"\"\"The cost function for logistic regression\"\"\"\n",
    "    p_1 = sigmoid(np.dot(X, theta)) # predicted probability of label 1\n",
    "    log_l = (-y)*np.log(p_1) - (1-y)*np.log(1-p_1) # log-likelihood vector\n",
    "\n",
    "    return log_l.mean()\n",
    "\n",
    "def grad(theta, X, y):\n",
    "    \"\"\"The gradient of the cost function for logistic regresssion\"\"\"\n",
    "    p_1 = sigmoid(np.dot(X, theta))\n",
    "    error = p_1 - y # difference between label and prediction\n",
    "    grad = np.dot(error, X) / y.size # gradient vector\n",
    "\n",
    "    return grad\n",
    "\n",
    "def train(X, y):\n",
    "    \"\"\"Train a logistic regression model for data X and labels y.\n",
    "    returns the learned parameter.\n",
    "    \"\"\"\n",
    "    theta = 0.1*np.random.randn(9)\n",
    "    theta_best = opt.fmin_bfgs(cost, theta, fprime=grad, args=(X, y))\n",
    "    return theta_best\n",
    "\n",
    "def predict(theta_best, Xtest):\n",
    "    \"\"\"Using the learned parameter theta_best, predict on data Xtest\"\"\"\n",
    "    p = sigmoid(theta_best.dot(Xtest.T))\n",
    "    for i in range(len(p)):\n",
    "        if p[i] > 0.5:\n",
    "            p[i] = 1\n",
    "        else:\n",
    "            p[i] = 0\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance measure\n",
    "\n",
    "There are many ways to compute the [performance of a binary classifier](http://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers). The key concept is the idea of a confusion matrix or contingency table:\n",
    "\n",
    "|              |    | Label |    |\n",
    "|:-------------|:--:|:-----:|:--:|\n",
    "|              |    |  +1   | -1 |\n",
    "|**Prediction**| +1 |    TP | FP |\n",
    "|              | -1 |    FN | TN |\n",
    "\n",
    "where\n",
    "* TP - true positive\n",
    "* FP - false positive\n",
    "* FN - false negative\n",
    "* TN - true negative\n",
    "\n",
    "Implemented three functions, the first one which returns the confusion matrix for comparing two lists (one set of predictions, and one set of labels). Then implemented two functions that take the confusion matrix as input and returns the **accuracy** and **balanced accuracy** respectively. Accuracy is defined as the number of correct classifications divided by the total number of examples. The balanced accuracy is the average accuracy of each class, that is the accuracy when the true class is positive and the accuracy when the true class is negative (averaged).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(prediction, labels):\n",
    "    \"\"\"Returns the confusion matrix for a list of predictions and (correct) labels\"\"\"\n",
    "    assert len(prediction) == len(labels)\n",
    "    def f(p, l):\n",
    "        n = 0\n",
    "        for i in range(len(prediction)):\n",
    "            if prediction[i] == p and labels[i] == l:\n",
    "                n += 1\n",
    "        return n\n",
    "    return np.matrix([[f(1, 1), f(1, 0)], [f(0, 1), f(0, 0)]])\n",
    "\n",
    "def confusion_matrix_advanced(prediction, labels):\n",
    "    \"\"\"Returns the confusion matrix for a list of predictions and (correct) labels\"\"\"\n",
    "    assert len(prediction) == len(labels)\n",
    "    f = lambda p, l: len(list(filter(lambda x: x == (p, l), zip(prediction, labels))))\n",
    "    return np.matrix([[f(1, 1), f(1, 0)], [f(0, 1), f(0, 0)]])\n",
    "\n",
    "def accuracy(cmatrix):\n",
    "    \"\"\"Returns the accuracy of a confusion matrix\"\"\"\n",
    "    tp, fp, fn, tn = cmatrix.flatten().tolist()[0]\n",
    "    return (tp + tn) / (tp + fp + fn + tn)\n",
    "\n",
    "def balanced_accuracy(cmatrix):\n",
    "    \"\"\"Returns the balanced accuracy of a confusion matrix\"\"\"\n",
    "    tp, fp, fn, tn = cmatrix.flatten().tolist()[0]\n",
    "    return tp / 2 / (tp + fn) + tn / 2 / (tn + fp)\n",
    "\n",
    "#M = confusion_matrix([1,1,1,-1,-1,-1],[1,1,-1,1,-1,-1])\n",
    "#accuracy(M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together\n",
    "\n",
    "Consider the following code, which trains on all the examples, and predicts on the training set. Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.470993\n",
      "         Iterations: 26\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7825520833333334, 0.736044776119403]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[:,0]\n",
    "X = data[:,1:]\n",
    "theta_best = train(X, y)\n",
    "pred = predict(theta_best, X)\n",
    "cmatrix = confusion_matrix(pred, y)\n",
    "[accuracy(cmatrix), balanced_accuracy(cmatrix)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of regularization parameter\n",
    "\n",
    "By splitting the data into two halves, train on one half and report performance on the second half. By repeating this experiment for different values of the regularization parameter $\\lambda$ we can get a feeling about the variability in the performance of the classifier due to regularization.$\\lambda$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "def split_data(data):\n",
    "    \"\"\"Randomly split data into two equal groups\"\"\"\n",
    "    np.random.seed(1)\n",
    "    N = len(data)\n",
    "    idx = np.arange(N)\n",
    "    np.random.shuffle(idx)\n",
    "    train_idx = idx[:int(N/2)]\n",
    "    test_idx = idx[int(N/2):]\n",
    "\n",
    "    X_train = data[train_idx, 1:]\n",
    "    t_train = data[train_idx, 0]\n",
    "    X_test = data[test_idx, 1:]\n",
    "    t_test = data[test_idx, 0]\n",
    "    \n",
    "    return X_train, t_train, X_test, t_test\n",
    "\n",
    "X_train, t_train, X_test, t_test = split_data(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
